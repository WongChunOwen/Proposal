---
title: "Team Project Proposal"
format: html
editor: visual
embed-resources: true
toc: true
toc-depth: 2
authors: [WONG CHUN OWEN, 
          ONG JU EN NIGEL,
          SHERWYN CHAN YIN KIT,
          ASHSYAHID BIN HUSSIN,
          LIM XUAN YU]
description: "Visualising the climate change over time"
---

For this document, the following packages are required:

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(knitr)
library(zoo)
```

# Original Data Visualization in Climate Change

The ongoing dialogue surrounding climate change has increasingly focused on the empirical data that underscores global temperature trends. [NOAA](https://www.ncei.noaa.gov/access/monitoring/monthly-report/global/202313){target="_blank"}'s recent visualization of global temperature anomalies from 1880 to 2023 offers a comprehensive view of the planet's warming trajectory. This project aims to elucidate the correlation between anthropogenic activities and climate change, highlighting how industrialization and carbon emissions have influenced global temperatures.

The visualization spans over a century of data, capturing periods of significant climatic shifts. Despite its clarity in depicting long-term trends, the inclusion of interactive features (as illustrated in @fig-GlobalLandOcean) enhances user engagement with the data. However, there is potential for further refinement. Incorporating more dynamic elements such as temporal sliders, geospatial overlays, and chloropleth map integration could offer a more nuanced understanding of how specific policies and global events impact climate change on a regional and global scale.

![Global Land and Ocean](../imgs/global_and_sea.png){#fig-GlobalLandOcean}

# Critical Assessment of the Original Visualization

The plot visualizes two variables: global temperature anomalies (quantitative) and time (categorical/DateTime). The x-axis represents time in years, while the y-axis shows the temperature anomalies in Celsius and Fahrenheit. The plot is intuitive and effectively communicates the overall trend of increasing global temperatures over time.

The chart is clear and easy to read, with temperature anomalies clearly dilineated by year. The use of blue and red colors to differentiate periods of negative and positive value temperature anomalies from the 20th century average of 13.9°C is contributes to the clarity of the plot.

The axes are well-labeled, and the inclusion of temperature anomalies in both Celsius and Fahrenheit on the right axis helps cater to different audiences. The chart covers a long historical period, providing a comprehensive view of temperature changes over time.

Overall the plot is effective in communicating the relationship between global temperature anomalies and time. However, there are shortcomings that the team has identified:

1.  **Interactivity**: The visualization lacks interactive features that would allow users to explore the data further, such as zooming in on specific time frames or regions, filtering data, or viewing additional information on specific data points.

2.  **Lack of Detail**: The chart does not provide specific values for each year, making it difficult to discern exact temperature anomalies.

3.  **Legend**: The chart lacks a legend to explain the color coding for positive and negative temperature anomalies.

4.  **Background**: The choice of background color may not be optimal for all users, and providing options for different color schemes would improve accessibility.

5.  **Color choice**: The use of red and blue colors to represent positive and negative temperature anomalies may not be accessible to colorblind users.

6.  **Cluttered data**: Displaying data in long time frame from 1850 to 2023 in a single chart may make it difficult to discern specific trends or patterns.

7.  **Context**: The visualization lacks context on different factors that may influence global temperature anomalies, such as regional variations, country-specific data, or the impact of specific events.

The observations above highlight areas where the original visualization could be improved to enhance user experience and provide a more comprehensive understanding of the data.

# Proposed Improvements

The original visualisation will be enhanced with the following features: 

- **Dynamic Range Slider**: A dynamic range slider will be added, allowing users to zoom into specific periods for detailed analysis or display a timelapse of temperature changes from 1930 to 2023. 

- **Customizable Metrics Selection**: A feature allowing users to choose which metrics to display, such as temperature changes or carbon emissions. 

- **Linked Graphs**: Display linked line or bar graphs below the choropleth map that update in real-time based on the selected country or region, showing detailed trends and data points. 

- **Predictive Model**: By adding a predictive model, users can visualise what the discernable future may hold for global warming.

## Choropleth Map Integration

Additionally, a choropleth map will be introduced to further visualize the rate of change of temperature by country: 

- **Data Representation**: Each country will have a set colour, with gradients shifting to reflect temperature changes over time. 

- **Interactive Tooltip**: Display detailed information about each country when hovered over, such as exact temperature changes, historical data, and other relevant metrics.

# Data Cleaning

```{r, message = FALSE, warning = FALSE}

# Load the data
data <- read_csv("../data/country_temp.csv")

# Convert the date column to Date format and extract the year and month
data$dt <- as.Date(data$dt, format = "%Y-%m-%d")
data$year <- as.numeric(format(data$dt, "%Y"))
data$month <- format(data$dt, "%m")

# Group by country, year, and month, then calculate the average temperatures rounded to 2 decimal points
monthly_avg_all_countries_initial <- data |>
  group_by(Country, year, month) |>
  summarize(monthly_avg = round(mean(AverageTemperature, na.rm = TRUE), 2))

# Display the tail of the initial data frame
knitr::kable(tail(monthly_avg_all_countries_initial), caption = "Tail of Monthly Average Temperatures by Country", digits = 2)

# Filter the data for Afghanistan in the year 1839
afghanistan_1839_initial <- monthly_avg_all_countries_initial |>
  filter(Country == "Afghanistan" & year == 1839)

# Display the filtered data
print(afghanistan_1839_initial)

# Check for NA and NaN values in the monthly_avg_all_countries_initial dataframe
nan_check_initial <- sapply(monthly_avg_all_countries_initial, function(x) sum(is.na(x)))
print(nan_check_initial)

# Display rows with NA and NaN values
rows_with_nan_initial <- monthly_avg_all_countries_initial[apply(monthly_avg_all_countries_initial, 1, function(row) any(is.na(row))), ]
print(rows_with_nan_initial)

# Remove rows with "Antarctica" from the dataset as the entire dataset for it is NaN
monthly_avg_all_countries_initial <- monthly_avg_all_countries_initial |> filter(Country != "Antarctica")

# Verify that "Antarctica" rows are removed
print(monthly_avg_all_countries_initial |> filter(Country == "Antarctica"))

# Function to fill NaN values using zoo library
# It is used for filling missing values through linear interpolation and forward/backward filling, ensuring continuous and complete temperature records.
fill_nan <- function(df) {
  df |>
    group_by(Country) |>
    mutate(monthly_avg = na.approx(monthly_avg, na.rm = FALSE, rule = 2)) |>
    mutate(monthly_avg = ifelse(is.na(monthly_avg), zoo::na.locf(monthly_avg, na.rm = FALSE), monthly_avg)) |>
    mutate(monthly_avg = ifelse(is.na(monthly_avg), zoo::na.locf(monthly_avg, fromLast = TRUE, na.rm = FALSE), monthly_avg)) |>
    ungroup()
}

# Apply fill_nan function
monthly_avg_all_countries_filled <- fill_nan(monthly_avg_all_countries_initial)

# Function to fill remaining NaN values with median of 5-year window for the same month
fill_with_window_month_median <- function(df) {
  df |>
    group_by(Country, month) |>
    mutate(monthly_avg = ifelse(is.na(monthly_avg), 
                                sapply(seq_along(monthly_avg), function(i) {
                                  if (is.na(monthly_avg[i])) {
                                    start_year <- year[i] - 5
                                    end_year <- year[i] + 5
                                    window_median <- median(df$monthly_avg[df$Country == Country[i] & df$month == month[i] & df$year >= start_year &df$year <= end_year & !is.na(df$monthly_avg)], na.rm = TRUE)
                                    return(window_median)
                                  } else {
                                    return(monthly_avg[i])
                                  }
                                }), 
                                monthly_avg)) |>
    ungroup()
}

# Apply window month median filling function
monthly_avg_all_countries_median <- fill_with_window_month_median(monthly_avg_all_countries_filled)

# Round the final dataframe to 2 decimal places
monthly_avg_all_countries_median <- monthly_avg_all_countries_median |>
  mutate(monthly_avg = round(monthly_avg, 2))

# Checking for remaining NaN values in the median imputed dataset
nan_check_median <- sapply(monthly_avg_all_countries_median, function(x) sum(is.na(x)))
print(nan_check_median)

# Display rows with NaN values in the median imputed dataset
rows_with_nan_median <- monthly_avg_all_countries_median[apply(monthly_avg_all_countries_median, 1, function(row) any(is.na(row))), ]
print(rows_with_nan_median)

# Filter the data for Afghanistan in the year 1839
afghanistan_1839_median <- monthly_avg_all_countries_median |>
  filter(Country == "Afghanistan" & year == 1839)

# Display the filtered data
print(afghanistan_1839_median)

```

## Joining with Country Codes

We will now join the cleaned data with the country codes dataset to obtain the alpha-2 and alpha-3 codes for each country. This will allow us to create a choropleth map with the country codes as identifiers. Let us check for countries with missing data after the join using column Alpha2 and clean the data accordingly.

```{r, message = FALSE, warning = FALSE}

country_codes <- read_csv("../data/country_codes.csv")


joinedDT <-
  full_join(
    monthly_avg_all_countries_median,
    country_codes,
    by = c("Country")
  )


missing_data <- joinedDT %>% filter(is.na(joinedDT$`Alpha2`))

unique_countries <- missing_data %>%
  distinct(Country, .keep_all = TRUE)

# Print the unique countries
# Display the tail of the initial data frame
knitr::kable(unique_countries, caption = "List of Unique Countries with no Country Codes")
```

With reference with the country code from IBAN [(ISO 3166)](https://www.iban.com/country-codes), we will adjust the format of the country from IBAN data set to the kaggle dataset [(Climate Change: Earth Surface Temperature Data, 2017)](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data/data)

```{r, message = FALSE, warning = FALSE}
country_codes$Country <- gsub("\\s*\\([^)]*\\)|\\s*\\[[^]]*\\]|\\s+Islands", "", country_codes$Country)

country_codes$Country <- gsub("Russian Federation", "Russia", country_codes$Country)
country_codes$Country <- gsub("United States of America", "United States", country_codes$Country)
country_codes$Country <- gsub("United Kingdom of Great Britain and Northern Ireland", "United Kingdom", country_codes$Country)
country_codes$Country <- gsub("Viet Nam", "Vietnam", country_codes$Country)
country_codes$Country <- gsub("Bonaire, Sint Eustatius and Saba", "Bonaire, Saint Eustatius And Saba", country_codes$Country)
country_codes$Country <- gsub("Myanmar", "Burma", country_codes$Country)
country_codes$Country <- gsub("Cabo Verde", "Cape Verde", country_codes$Country)
country_codes$Country <- gsub("Czechia", "Czech Republic", country_codes$Country)
country_codes$Country <- gsub("Côte d'Ivoire", "Côte D'Ivoire", country_codes$Country)
country_codes$Country <- gsub("Micronesia", "Federated States Of Micronesia", country_codes$Country)
country_codes$Country <- gsub("French Southern Territories", "French Southern And Antarctic Lands", country_codes$Country)
country_codes$Country <- gsub("Guinea-Bissau", "Guinea Bissau", country_codes$Country)
country_codes$Country <- gsub("Heard Island and McDonald", "Heard Island And Mcdonald", country_codes$Country)
country_codes$Country <- gsub("Isle of Man", "Isle Of Man", country_codes$Country)
country_codes$Country <- gsub("Macao", "Macau", country_codes$Country)
country_codes$Country <- gsub("Republic of North Macedonia", "Macedonia", country_codes$Country)
country_codes$Country <- gsub("Palestine, State of", "Palestina", country_codes$Country)

country_codes$Country <- gsub("Saint Vincent and The Grenadines", "Saint Vincent And The Grenadines", country_codes$Country)
country_codes$Country <- gsub("South Georgia And The South Sandwich", "South Georgia And The South Sandwich Isla", country_codes$Country)
country_codes$Country <- gsub("Syrian Arab Republic", "Syria", country_codes$Country)
country_codes$Country <- gsub("Tanzania, United Republic of", "Tanzania", country_codes$Country)
country_codes$Country <- gsub("Timor-Leste", "Timor Leste", country_codes$Country)
country_codes$Country <- gsub(" and ", " And ", country_codes$Country)


monthly_avg_all_countries_median$Country <- gsub("\\s*\\([^)]*\\)|\\s*\\[[^]]*\\]|\\s+Islands", "",monthly_avg_all_countries_median$Country)
```

Ensure that there are no more country missing from IBAN [(ISO 3166)](https://www.iban.com/country-codes)

```{r, message = FALSE, warning = FALSE}
joinedDT <-
  full_join(
    monthly_avg_all_countries_median,
    country_codes,
    by = c("Country")
  )


missing_data <- joinedDT %>% filter(is.na(joinedDT$`Alpha2`))

unique_countries <- missing_data %>%
  distinct(Country, .keep_all = TRUE)

# Print the unique countries
# Display the tail of the initial data frame
knitr::kable(unique_countries, caption = "List of Unique Countries with no Country Codes")
```

Then display the final cleaned data

```{r, message = FALSE, warning = FALSE}
innerjoinedDT <-
  inner_join(
    monthly_avg_all_countries_median,
    country_codes,
    by = c("Country")
  )


# Check the cleaned data
knitr::kable(head(innerjoinedDT), caption = "Cleaned Data Joined with Country Codes")

```

# Conclusion

The data is now ready for visualization. The next step will be to create a plot that can effectively communicate the relationship between global temperature anomalies and anthropogenic activities over time, and additionally allow curious readers to explore the data even further using interactivity. We will use Plotly to create the plot and add interactivity.

###### References

::: {style="font-size: 12px"}
NCEI.Monitoring.Info\@noaa.gov. (n.d.). Annual 2023 Global Climate Report \| National Centers for Environmental Information (NCEI). <https://www.ncei.noaa.gov/access/monitoring/monthly-report/global/202313>

List of country codes by alpha-2, alpha-3 code (ISO 3166). (n.d.). <https://www.iban.com/country-codes>

Change, N. G. C. (n.d.). Global Surface Temperature \| NASA Global Climate Change. Climate Change: Vital Signs of the Planet.<https://climate.nasa.gov/vital-signs/global-temperature/?intent=121>

Climate change: Earth surface temperature data. (2017, May 1). Kaggle. <https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data/data>
:::
